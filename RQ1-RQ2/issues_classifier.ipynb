{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb61519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tokens_utils import *\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "token = os.getenv(\"GITHUB_TOKEN\")\n",
    "url = 'https://api.github.com/graphql'\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17c398c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_issue(number, title, body, comments):\n",
    "    prompt = f\"\"\"\n",
    "As a highly skilled software engineer and open source repository maintainer, your task is to categorize a closed GitHub issue into one of the following categories: 'bug', 'feature', 'question', 'build issue', 'documentation', or 'other'. Make your determination based on the issue’s title, body, and any available comments.\n",
    "\n",
    "Begin with a concise checklist (3-7 bullets) of what you will do; keep items conceptual, not implementation-level. After categorization, verify that your choice aligns with the schema, and if not, clarify any ambiguity before finalizing.\n",
    "\n",
    "Checklist (conceptual steps):\n",
    "- Review the title, body, and comments for evidence supporting any category.\n",
    "- Match findings against the provided category definitions.\n",
    "- Identify keywords or phrases in each section that support classification.\n",
    "- Assess whether the issue was fixed (if applicable) and note any relevant commit or PR references.\n",
    "- Check whether the issue is a duplicate and identify the original issue number if so.\n",
    "- If comments are absent, rely solely on the title and body and document any resulting limitations.\n",
    "\n",
    "## Issue Details\n",
    "Title: {title}\n",
    "Body: {body}\n",
    "Comments: {comments}\n",
    "\n",
    "## Category Definitions\n",
    "- **bug:** Reports unexpected or faulty behavior requiring developer intervention. Examples: \"unexpected error\", \"crash when...\", \"fails to...\", \"does not work as expected\". Intent or expected result may be described. Maintainers may confirm, provide a fix, or reference a commit/PR. Bugs refer to runtime/functional issues and not build/compilation errors.\n",
    "- **feature:** Requests improvements or new functionality not tied to defects. Indicates a desired enhancement or new outcome. Examples: \"add support for...\", \"feature request\", \"implement...\".\n",
    "- **question:** Inquires about usage, behavior, or outcomes; resolves with clarification, often due to misconfiguration or misunderstanding. Examples: \"how do I...\", \"usage question\", \"is it correct behavior?\", \"Am I missing something or is it a bug?\".\n",
    "- **build issue:** Involves problems building or compiling, often with configuration details. Solutions may require new configs or versions. If the resolution necessitated code changes (beyond build configs), categorize as 'bug'. Examples: \"build fails with...\", \"compilation error\", \"cannot install\". Build issues are specific to installation, compilation, or setup processes.\n",
    "- **documentation:** Relates to outdated info, errors, typos, or inconsistencies between docs and code. May reference PRs, but not code-level defects. Examples: \"documentation outdated\", \"clarify docs\", \"readme error\".\n",
    "- **other:** Use only if none of the above categories apply.\n",
    "\n",
    "## Instructions\n",
    "- Clearly explain your reasoning for the chosen category.\n",
    "- Cite specific evidence from the issue’s title, body, and (if applicable) comments to support the classification.\n",
    "- Indicate if the issue was fixed, and provide the relevant commit or PR reference, or an empty string if none exists.\n",
    "- If the issue is a duplicate, specify the original issue number; otherwise, use null.\n",
    "- If comments are missing, base your rationale on the available information and declare the limitation.\n",
    "\n",
    "After categorization, validate that your classification, rationale, and evidence conform exactly to the required output schema. Revise or adjust before final response if validation fails.\n",
    "\n",
    "## Output Format\n",
    "Return a JSON object strictly following this schema and key order:\n",
    "\n",
    "{{\n",
    "    \"classification\": string,           // One of: 'bug', 'feature', 'question', 'build issue', 'documentation', 'other'\n",
    "    \"rationale\": string,                // Concrete reason for your classification decision in one sentence\n",
    "    \"fixed\": boolean,                   // True if the issue was fixed, false otherwise\n",
    "    \"fix_commit_or_pr\": string,         // Link/reference to fix commit or PR, or empty string\n",
    "    \"duplicate_of\": string|null         // Original issue number if duplicate, null otherwise\n",
    "}}\n",
    "\n",
    "If a field (title, body, or comments) is empty or missing, summarize with what's present and mention any limitations in your rationale or evidence summaries. Maintain the specified key and field order.\n",
    "\n",
    "Example Response:\n",
    "{{\n",
    "    \"classification\": \"bug\",\n",
    "    \"rationale\": \"The issue describes a wrong call of power instead of square for structured arrays.\",\n",
    "    \"fixed\": true,\n",
    "    \"fix_commit_or_pr\": \"PR #29392\",\n",
    "    \"duplicate_of\": null\n",
    "}}\n",
    "\n",
    "Please ensure your final response is a valid JSON object that adheres strictly to the schema and key order provided above.\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-5-mini-2025-08-07\",\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert software developer\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=1\n",
    "    )\n",
    "    \n",
    "    return number, response.choices[0].message.content\n",
    "\n",
    "def execute_model_for_issues(df, repo):\n",
    "    BATCH_SIZE = 100\n",
    "    MAX_WORKERS = 64\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        futures = []\n",
    "        for idx, row in df.iterrows():\n",
    "            futures.append(executor.submit(classify_issue, row[\"number\"], row['title'], row['bodyText'], row['comments']))\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            number, classification_result = future.result()\n",
    "            results.append(json.loads(f'{{\"number\": {number}, \"classification\": {classification_result}}}'))\n",
    "            if len(results) % BATCH_SIZE == 0:\n",
    "                print(f\"Processed {len(results)} issues.\")\n",
    "                export_classification_to_json(results, f\"{repo}_{len(results)}\")\n",
    "            time.sleep(2) \n",
    "    return results\n",
    "\n",
    "def export_classification_to_json(results, repo):\n",
    "    output_file = f\"{repo}_classification.json\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        json.dump(results, f, indent=4)\n",
    "    print(f\"Classification results saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ff6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 100 issues.\n",
      "Classification results saved to pytorch_100_classification.json\n",
      "Processed 200 issues.\n",
      "Classification results saved to pytorch_200_classification.json\n",
      "Processed 300 issues.\n",
      "Classification results saved to pytorch_300_classification.json\n",
      "Processed 400 issues.\n",
      "Classification results saved to pytorch_400_classification.json\n",
      "Processed 500 issues.\n",
      "Classification results saved to pytorch_500_classification.json\n",
      "Processed 600 issues.\n",
      "Classification results saved to pytorch_600_classification.json\n",
      "Processed 700 issues.\n",
      "Classification results saved to pytorch_700_classification.json\n",
      "Processed 800 issues.\n",
      "Classification results saved to pytorch_800_classification.json\n",
      "Processed 900 issues.\n",
      "Classification results saved to pytorch_900_classification.json\n",
      "Processed 1000 issues.\n",
      "Classification results saved to pytorch_1000_classification.json\n",
      "Processed 1100 issues.\n",
      "Classification results saved to pytorch_1100_classification.json\n",
      "Processed 1200 issues.\n",
      "Classification results saved to pytorch_1200_classification.json\n",
      "Processed 1300 issues.\n",
      "Classification results saved to pytorch_1300_classification.json\n",
      "Processed 1400 issues.\n",
      "Classification results saved to pytorch_1400_classification.json\n",
      "Processed 1500 issues.\n",
      "Classification results saved to pytorch_1500_classification.json\n",
      "Processed 1600 issues.\n",
      "Classification results saved to pytorch_1600_classification.json\n",
      "Processed 1700 issues.\n",
      "Classification results saved to pytorch_1700_classification.json\n",
      "Processed 1800 issues.\n",
      "Classification results saved to pytorch_1800_classification.json\n",
      "Processed 1900 issues.\n",
      "Classification results saved to pytorch_1900_classification.json\n",
      "Processed 2000 issues.\n",
      "Classification results saved to pytorch_2000_classification.json\n",
      "Processed 2100 issues.\n",
      "Classification results saved to pytorch_2100_classification.json\n",
      "Processed 2200 issues.\n",
      "Classification results saved to pytorch_2200_classification.json\n",
      "Processed 2300 issues.\n",
      "Classification results saved to pytorch_2300_classification.json\n",
      "Processed 2400 issues.\n",
      "Classification results saved to pytorch_2400_classification.json\n",
      "Processed 2500 issues.\n",
      "Classification results saved to pytorch_2500_classification.json\n",
      "Processed 2600 issues.\n",
      "Classification results saved to pytorch_2600_classification.json\n",
      "Processed 2700 issues.\n",
      "Classification results saved to pytorch_2700_classification.json\n",
      "Processed 2800 issues.\n",
      "Classification results saved to pytorch_2800_classification.json\n",
      "Processed 2900 issues.\n",
      "Classification results saved to pytorch_2900_classification.json\n",
      "Processed 3000 issues.\n",
      "Classification results saved to pytorch_3000_classification.json\n",
      "Processed 3100 issues.\n",
      "Classification results saved to pytorch_3100_classification.json\n",
      "Processed 3200 issues.\n",
      "Classification results saved to pytorch_3200_classification.json\n",
      "Processed 3300 issues.\n",
      "Classification results saved to pytorch_3300_classification.json\n",
      "Processed 3400 issues.\n",
      "Classification results saved to pytorch_3400_classification.json\n",
      "Processed 3500 issues.\n",
      "Classification results saved to pytorch_3500_classification.json\n",
      "Processed 3600 issues.\n",
      "Classification results saved to pytorch_3600_classification.json\n",
      "Processed 3700 issues.\n",
      "Classification results saved to pytorch_3700_classification.json\n",
      "Classification results saved to pytorch_3767_classification.json\n"
     ]
    }
   ],
   "source": [
    "# We recommend to do this analysis project by project. \n",
    "repo = \"pytorch\"\n",
    "df_issues = pd.read_pickle(f\"issues_per_project/{repo}.pkl\")\n",
    "results = execute_model_for_issues(df_issues, repo)\n",
    "export_classification_to_json(results, f\"{repo}_{len(results)}\")\n",
    "\n",
    "# The results of this categorization can be found in json files per project\n",
    "# Go to: RQ1/issues_classification_json/ or RQ1/issues_classification_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da73a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-git",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
